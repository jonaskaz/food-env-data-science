---
title: "Food Environmental Predictors of County Level Diabetes Rates"
author: "Jonas Kazlauskas and Shawn Albertson"
date: "12/15/2020"
output:
  github_document:
    toc: true
---
## Introduction  

*talk about uncertainty in the data itself here?*
This dataset we used for our analysis is the Food Environment Atlas, taken from the USDA Economic Research Service. This datatset contains information on a number of food related environmental factors such as proximity to stores, food prices, food assistance programs, local food availability. It also includes data on factors that may be related to these such as obesity rate, diabetes rate, and physical activity. This data is provided on the country level across the United States. The purpose of the food environment atlas is to foster research in these areas, and give an overview of food access and health.

The data for the Food Environment Atlas is largely taken from CDC estimates. The CDC uses data from the Behavioral Risk Factor Surveillance System which is under the US Census Bureau to make estimates. 


Diabetes rate in this dataset is defined as the rate (percent) of persons over 20 years old with a BMI over 30 within each county. We compared this rate at the county level between other factors in this dataset such as proximity to grocery stores, food insecurity, socioeconomic factors and more to determine the best predictors.

Background Research:
Obesity:
Defined as everyone above 20 years old with a BMI over 30. 
Data comes from the CDC and the CDC made their estimates using data from the Behavioral Risk Factor Surveillance System which is under the US Census Bureau

Diabetes:
Estimates for people over 20 with diabetes
Data comes from the CDC and the CDC made their estimates using data from the Behavioral Risk Factor Surveillance System which is under the US Census Bureau

## Our question
We set out to answer the question:  What are the best predictors of adult diabetes rate in the US?

## Initial EDA

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library("readxl")
library(glmnet)
library(broom)
```

```{r load data}
path <- "data/FoodEnvironmentAtlas.xls"
# Create a list of dataframes from every sheet in the .xls file
full_list <- path %>%
  excel_sheets() %>%
  set_names() %>%
  map(read_excel, path = path)

# Create a modified list of the dataframes to only include ones with `FIPS` columns
fips_list <- full_list[c(3, 5:10, 12, 13)]

# Create a single dataframe with all parameters for all counties
df_full_fips <- 
  fips_list %>% 
  reduce(inner_join, by = c("FIPS"))
```


The most obvious thing to notice from is the fact that this dataset includes a lot of different statistics. Specifically, there are 311 statistics reported for 3140 FIPS codes. We also looked at some summary statistics for `PCT_DIABETES_ADULTS13` which contains the percentage rates of diabetes diagnosed in adults in each county in 2013. We can see that the mean diabetes rate is about 11.24%, which is slightly higher than the CDC's 2020 estimate of national diabetes rate at 10.2% [6]. A histogram allows us to visualize the distribution that diabetes rate takes across all counties. The distribution looks roughly normal. Interestingly, when we isolate the counties with the ten highest diabetes rates, we find that they are all in Alabama or South Carolina. Nine out of ten are counties in Alabama, while the other is in South Carolina. 

```{r EDA}
df_full_fips %>% 
  dim()

df_full_fips %>%
  select(PCT_DIABETES_ADULTS13) %>% 
  summary()

df_full_fips %>% 
  select(c("County.x", "State.x", "PCT_DIABETES_ADULTS13")) %>% 
  arrange(desc(PCT_DIABETES_ADULTS13)) %>% 
  head(10)

df_full_fips %>%
  select(PCT_DIABETES_ADULTS13) %>% 
  ggplot() +
  geom_histogram(aes(x = PCT_DIABETES_ADULTS13), binwidth = .5, boundary = 10) +
  xlab("Percent of Adults Diagnosed with Diabetes")
```

## Methodology
In order to isolate the most important factors in a model to predict diabetes, we used a technique called lasso regression. Lasso regression is a form of **regularization**, which describes a family of techniques that help your model effectively balance **bias** and **variance**. In other words, a model should be optimized such that it is neither **underfit** (high bias) or **overfit** (high variance).


Key to using lasso regression is splitting data into a training set and a testing set. The training set is used to inform the coefficients of a linear model, while the testing set is used to evaluate how well those coefficients work on separate data. 


```{r split data into test and train}
df_full <- 
  df_full_fips %>% 
  select(-c("FIPS", matches("State"), matches("County"), "PCT_DIABETES_ADULTS08"))

# create a matrix of all the predictors in df_full
# This also makes everything numeric and turns qualitative data into dummy vars
x_vars <- model.matrix(PCT_DIABETES_ADULTS13~. , df_full)[,-1]

# Pull diabetes rates into a list
y_var <- df_full$PCT_DIABETES_ADULTS13

# Set sampling random seed
set.seed(4)

train = sample(1:nrow(x_vars), nrow(x_vars)/2)

training_data_x <- x_vars[train,]
training_data_y <- y_var[train]
```


One way to overfit a model is to give too much weight to factors in the training data which in reality don't have a large impact on the result. On the other hand, eliminating too many features of a model may be oversimplified and have high bias. Lasso regression introduces a parameter `lambda` which penalizes high correlation coefficients.

```{r}
# setup a sequence of lambda values to go through.
lambda_seq <- 10^seq(2, -2, by = -.1)

# x_test is indexes
x_test = (-train)

# y_test is values
y_test = y_var[x_test]
```

```{r}
cv_output = cv.glmnet(training_data_x,
                   training_data_y,
                   alpha = 1,
                   lambda = lambda_seq) # Fit lasso model on training data
plot(cv_output) # Draw plot of training MSE as a function of lambda
cv_output
```

```{r}
# Create model with minimum lambda value
lambda_min <- cv_output$lambda.min
lasso_min <- glmnet(x_vars[train,], y_var[train], alpha = 1, lambda = lambda_min)
pred_min <- predict(lasso_min, s = lambda_min,  newx = x_vars[x_test,])

lasso_min %>% 
  tidy() %>%
  mutate(est_ab = abs(estimate)) %>%
  arrange(desc(est_ab))


# lasso_min %>% 
#   tidy() %>% 
#   arrange(desc(estimate)) %>% 
#   mutate(estimate = abs(estimate))

# # Create model with 1se lambda value
# lambda_1se <- cv_output$lambda.1se
# lasso_1se <- glmnet(x_vars[train,], y_var[train], alpha = 1, lambda = lambda_1se)
# pred_1se <- predict(lasso_1se, s = lambda_1se,  newx = x_vars[x_test,])
# 
# lasso_1se %>%
#   tidy() %>%
#   arrange(desc(estimate))

# Create dataframe with predictions from both models compared with actual values
# final <- cbind(y_var[x_test], pred_min)

# as.tibble(final) %>%
#   rename(
#     "predicted" = "1",
#     "actual" = "V1"
#     ) 
```







## What are the best predictors? - Shawn
*what they are, why that might be the case*

## How good is this model for predicting diabetes rates? 
*MSE or Rsquared values*- Shawn
*confidence interval (CI or PI?? (probably CI)) of lasso model* - Jonas
*CI for the lambda itself(?)* - Shawn

## Plots - Jonas
*maybe here, maybe scattered throughout*

## Uncertainty
*address sources of uncertainty which are potentially outside the scope of what's already been discussed*

## Conclusion - Shawn



## Sources
[1] https://www.ers.usda.gov/data-products/food-environment-atlas/data-access-and-documentation-downloads/#Current%20Version  
[2] https://www.ers.usda.gov/webdocs/DataFiles/80526/2017%20Food%20Environment%20Atlas%20Documentation.pdf?v=1143.5  
[3] https://rstatisticsblog.com/data-science-in-action/machine-learning/lasso-regression/  
[4] https://www.steveklosterman.com/over-under/  
[5] http://www.science.smith.edu/~jcrouser/SDS293/labs/lab10-r.html  
[6] https://www.cdc.gov/diabetes/pdfs/data/statistics/national-diabetes-statistics-report.pdf
[7] https://cran.r-project.org/web/packages/glmnet/glmnet.pdf
[8] https://www.pluralsight.com/guides/linear-lasso-and-ridge-regression-with-r


