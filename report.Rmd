---
title: "Food Environmental Predictors of County Level Diabetes Rates"
author: "Jonas Kazlauskas and Shawn Albertson"
date: "12/15/2020"
output:
  github_document:
    toc: true
---
## Introduction  

*talk about uncertainty in the data itself here?*
The first dataset we used for our analysis is the Food Environment Atlas, taken from the USDA Economic Research Service. This datatset contains information on a number of food related environmental factors such as proximity to stores, food prices, food assistance programs, local food availability. It also includes data on factors that may be related to these such as obesity rate, diabetes rate, and physical activity. This data is provided on the country level across the United States. The purpose of the food environment atlas is to foster research in these areas, and give an overview of food access and health.The data for the Food Environment Atlas is largely taken from CDC estimates. The CDC uses data from the Behavioral Risk Factor Surveillance System which is under the US Census Bureau to make estimates. 

We combined this dataset with 2018 county level diabetes data taken from the CDC. We chose to use this data as it was more recent than what was included in the Environmental Atlas, but ultimately came from the same source. This data is from a reputable government source, and we expect it to display accurate data. 

Diabetes rate in this dataset is defined as the rate (percent) of persons over 18 years old with a BMI over 30 within each county. We compared this rate at the county level between other factors in this dataset such as proximity to grocery stores, food insecurity, socioeconomic factors and more to determine the best predictors.

## Our question
We set out to answer the question:  What are the best predictors of adult diabetes rate in the US?

## Initial EDA

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library("readxl")
library(glmnet)
library(broom)
library(forcats)
```

```{r load data}
path <- "data/FoodEnvironmentAtlas.xls"
# Create a list of dataframes from every sheet in the Food Environment Atlas
full_list <- path %>%
  excel_sheets() %>%
  set_names() %>%
  map(read_excel, path = path)

# Get updated county level diabetes rates for 2018
diabetes_path <- "data/diabetes2018.csv"
df_diabetes18 <- 
  read_csv(
    diabetes_path,
    skip = 2
  ) %>% 
  rename(
    "FIPS" = County_FIPS, 
    "diabetes18" = "Diagnosed Diabetes Percentage"
    ) %>% 
  select(c(FIPS, diabetes18)) %>% 
  mutate(FIPS = ifelse(nchar(FIPS) == 4, paste("0", FIPS, sep = ""), FIPS))

# Add new diabetes data to list of data frames
full_list[[length(full_list)]] <- df_diabetes18

# Create a modified list of the dataframes to only include ones with `FIPS` columns
fips_list <- full_list[c(3, 5:10, 12:length(full_list))]

# Create a single dataframe with all parameters for all counties
df_full_fips <- 
  fips_list %>% 
  reduce(inner_join, by = c("FIPS"))

# Remove columns from dataframe that are not valid predictors. In our case, we remove columns that are geographic in nature or contain data also describing diabetes.
df_full <- 
  df_full_fips %>% 
  select(-c("FIPS", matches("State"), matches("County"), "PCT_DIABETES_ADULTS08", "PCT_DIABETES_ADULTS13"))
```

The most obvious thing to notice from is the fact that this dataset includes a lot of different statistics. Specifically, there are 177 statistics reported for 3139 FIPS codes. We also looked at some summary statistics for `diabetes18` which contains the percentage rates of diabetes diagnosed in adults in each county in 2018. We can see that the mean diabetes rate is about 8.72%, which is slightly higher than the CDC's 2020 estimate of national diabetes rate at 10.2% [6]. A histogram allows us to visualize the distribution that diabetes rate takes across all counties. The distribution looks roughly lognormal, with the peak shifted below the mean. When we isolate the counties with the ten highest diabetes rates, we find a range of states, but three out of the ten listed are actually in South Dakota. 

```{r EDA}
df_full %>% 
  dim()

df_full_fips %>%
  select(diabetes18) %>% 
  summary()

df_full_fips %>% 
  select(c("County.x", "State.x", "diabetes18")) %>% 
  arrange(desc(diabetes18)) %>% 
  head(10)

df_full_fips %>%
  select(diabetes18) %>% 
  ggplot() +
  geom_histogram(aes(x = diabetes18), binwidth = .5, boundary = 10) +
  xlab("Percent of Adults Diagnosed with Diabetes")
```

## Methodology
In order to isolate the most important factors in a model to predict diabetes, we used a technique called lasso regression. Lasso regression is a form of **regularization**, which describes a family of techniques that help your model effectively balance **bias** and **variance**. In other words, a model should be optimized such that it is neither **underfit** (high bias) nor **overfit** (high variance). One way to overfit a model is to make coefficients which are too high, leading to a model which works very well for a training data but not as well on yet unseen data. On the other hand, eliminating too many features of a model may be oversimplified and have high bias.

We used the `glmnet` package in R to do lasso regression. This package depends on us creating a **design matrix** rather than inputting a dataframe directly. We use the function `model.matrix` to compute the design matrix for the linear model predicting `diabetes18` using every other column and every observed county. This function removes rows with `NA` values from the dataframe, so the result is somewhat shorter than the input. The use of `glmnet` also depends on creating a list of the values we want to predict.

```{r create design matrix}
# Create a matrix of all the predictors in df_full
# This also makes everything numeric and turns qualitative data into dummy vars.
x_vars <- model.matrix(diabetes18~. , df_full)

# Pull diabetes rates into a list
y_var <- df_full$diabetes18
```

Key to using lasso regression is splitting data into a training set and a testing set. The training set is used to inform the coefficients of a linear model, while the testing set is used to evaluate how well those coefficients work on data which is not used to develop the model itself.

```{r split data into test and train}
# Set sampling random seed
set.seed(4)

# Train is a list of indexes from where training data is taken
train = sample(1:nrow(x_vars), nrow(x_vars)/2)

training_data_x <- x_vars[train,]
training_data_y <- y_var[train]

# x_test is indexes where training data is NOT taken
x_test = (-train)

# y_test is values at testing indexes
y_test = y_var[x_test]
```

Lasso regression introduces a parameter `lambda` which penalizes high correlation coefficients. A higher lambda value penalizes high regression coefficients more, resulting in a model with lower overall regression coefficients and high bias. Increasingly higher lambda values reduces the weakest correlation coefficients to zero, and in theory an infinitely high lambda value should *reduce all regression coefficients to zero*. 

A lower lambda value penalizes high regression coefficients less, resulting in higher overall coefficients and high variance. The following image shows a representation of what this might look like for a single variable, and a similar thing happens in higher dimensions. In lasso regression, a range of lambda values are tested in order to find the ideal tradeoff between bias and variance. 

![bias-variance](bias_variance.png)


```{r test a range of lambdas}
# setup a sequence of lambda values to go through.
lambda_seq <- 10^seq(2, -2, by = -.1)

# Call glmnet function
cv_output = cv.glmnet(training_data_x,
                   training_data_y,
                   alpha = 1,
                   lambda = lambda_seq) # Fit lasso model on training data
plot(cv_output) # Draw plot of training MSE as a function of lambda
cv_output
```
The plot above shows the MSE of the model outcome for different `lambda` values. The top of the graph lists the number of predictors left for every value of lambda. At the lowest values of lambda, the greatest number of predictors is used, but this leads to an overfit model. Eventually, all predictors are dropped to zero and the model is ineffective. An ideal model uses a `lambda` which minimizes the MSE. 

```{r}
# Create model with minimum lambda value
lambda_min <- cv_output$lambda.min
lasso_min <- glmnet(x_vars[train,], y_var[train], alpha = 1, lambda = lambda_min)
pred_min <- predict(lasso_min, s = lambda_min,  newx = x_vars[x_test,])

lasso_min %>% 
  tidy() %>%
  mutate(est_ab = abs(estimate)) %>%
  arrange(desc(est_ab))

```



## What are the best predictors? - Shawn
*what they are, why that might be the case*

## How good is this model for predicting diabetes rates? 
To evaluate our model, we can find the mean squared error between our predicted values and actual values.

```{r echo = FALSE}
final <- as.tibble(cbind(y_var[x_test], pred_min)) %>%
  rowid_to_column("Index") %>%
  rename('Actual' = V1, "Predicted" = "1")
```

```{r}
mse <- mean((final$Predicted - final$Actual)^2)
mse
```

Our mean squared error is 2.713. This tells us our model has a fairly significant error, and we cannot expect to predict the the diabetes rate with high accuracy. However, this also tells us that the predictors we found can help to predict general trends in the diabetes rate. 


*confidence interval (CI or PI?? (probably CI)) of lasso model* - Jonas

We noticed that our lasso model outputs varying correlation coefficients when ran multiple times. To account for this variation, we decided to perform a bootstrap to find a confidence interval for each of our correlation coefficients. We used the library HDCI to perform the bootstrap. The results are shown below, with any perdictor with intervals that included 0 removed to focus on our top predictors. We noticed that for larger estimates, their confidence interval range tended to be larger.

```{r}
library(HDCI)
CI = bootLasso(x_vars[train,], y_var[train], alpha = 0.05)
```


```{r echo=FALSE}

intervals <-
  as.tibble(CI$interval) %>%
  tidy() %>%
  filter(min != 0,
         max != 0,
         min >= 0 | min <= 0 & max <= 0) %>%
  mutate(abs_est = abs(mean)) %>%
  arrange(desc(abs_est)) %>%
  tail(-1)

coef_conf <- lasso_min %>%
  tidy() %>%
  mutate(est_ab = abs(estimate)) %>%
  arrange(desc(est_ab)) %>%
  tail(-1) %>%
  head(-27)
coef_conf
est_intervals <- intervals %>%
  cbind(coef_conf) %>%
  head(-1)
est_intervals

```

```{r}
est_intervals %>%
  select(
    term,
    estimate,
    est_ab,
    min,
    max
  )
```


*CI for the lambda itself(?)* - Shawn

## Plots 
Shown below is the top predictors of diabetes rate in the US that we found, with their associated confidence interval. 
```{r echo=FALSE}
theme_interval <- function() {
  theme_minimal() %+replace%
  theme(
    axis.text.x = element_text(size = 9, angle = 90, hjust = 0.95),
    axis.text.y = element_text(size = 12),
    axis.title.x = element_text(margin = margin(4, 4, 4, 4), size = 16),
    axis.title.y = element_text(margin = margin(4, 4, 4, 4), size = 16, angle = 90),
    legend.title = element_text(size = 16),
    legend.text = element_text(size = 16),
    strip.text.x = element_text(size = 12),
    strip.text.y = element_text(size = 12),
    panel.grid.major = element_line(color = "grey90"),
    panel.grid.minor = element_line(color = "grey90"),
    aspect.ratio = 4 / 10,
    plot.margin = unit(c(t = +0, b = +0, r = +0, l = +0), "cm"),
    plot.title = element_text(size = 18),
    plot.title.position = "plot",
    plot.subtitle = element_text(size = 16),
    plot.caption = element_text(size = 12)
  )
}
```


| Variables           | Meaning                                           | Estimate |
|---------------------|---------------------------------------------------|----------|
| SUPERCPTH16         | Supercenters & club stores, 2016                  | 3.382    |
| SNAP_REPORTSIMPLE09 | SNAP simplified reporting, 2009*                  | -2.482   |
| PCHWICWOMEN_14_16   | WIC women participants (change % women), 2014-16* | 2.093    |
| SUPERCPTH11         | Supercenters & club stores, 2011                  | 1.771    |
| SNAP_OAPP16         | SNAP online application, 2016*                    | -1.465   |
| RECFACPTH16         | Recreation & fitness facilities/1,000 pop, 2016   | -1.0271  |
| WICSPTH16           | WIC-authorized stores/1,000 pop, 2016             | -1.004   |
| RECFAPTH11          | Recreation & fitness facilities/1,000 pop, 2011   | -0.526   |
| FFRPTH11            | Full-service restaurants/1,000 pop, 2011          | -0.361   |
| FFRPTH16            | Fast-food restaurants/1,000 pop, 2016             | -0.297   |
| CHIPSTAX_VENDM14    | Chip & pretzel sales tax, vending, 2014*          | -0.147   |




```{r}
est_intervals %>%
  head(-7) %>%
  mutate(term = fct_reorder(term, est_ab)) %>%
  ggplot(aes(term, est_ab)) +
  geom_errorbar(aes(ymin=est_ab -(range/2), ymax=est_ab +(range/2)), width=.1, color = "red") +
  geom_point() +
  theme_interval() +
  labs(title="\n Top Predictors of US Diabetes Rate \n",
       x = "Predictor",
       y = "Magnitude of \n Correlation Coefficient \n")
```

| Variables           | Meaning                                           |
|---------------------|---------------------------------------------------|
| SUPERCPTH16         | Supercenters & club stores, 2016                  |
| SNAP_REPORTSIMPLE09 | SNAP simplified reporting, 2009*                  |
| PCHWICWOMEN_14_16   | WIC women participants (change % women), 2014-16* |
| SUPERCPTH11         | Supercenters & club stores, 2011                  |
| SNAP_OAPP16         | SNAP online application, 2016*                    |
| RECFACPTH16         | Recreation & fitness facilities/1,000 pop, 2016   |
| WICSPTH16           | WIC-authorized stores/1,000 pop, 2016             |
| RECFAPTH11          | Recreation & fitness facilities/1,000 pop, 2011   |
| FFRPTH11            | Full-service restaurants/1,000 pop, 2011          |
| FFRPTH16            | Fast-food restaurants/1,000 pop, 2016             |
| CHIPSTAX_VENDM14    | Chip & pretzel sales tax, vending, 2014*          |



```{r echo=FALSE}
theme_error <- function() {
  theme_minimal() %+replace%
  theme(
    axis.text.x = element_text(size = 10, angle = 90),
    axis.text.y = element_text(size = 12),
    axis.title.x = element_text(margin = margin(4, 4, 4, 4), size = 16),
    axis.title.y = element_text(margin = margin(4, 4, 4, 4), size = 16, angle = 90),
    legend.title = element_text(size = 16),
    legend.text = element_text(size = 12),
    strip.text.x = element_text(size = 12),
    strip.text.y = element_text(size = 12),
    panel.grid.major = element_line(color = "grey90"),
    panel.grid.minor = element_line(color = "grey90"),
    aspect.ratio = 7 / 11,
    plot.margin = unit(c(t = +0, b = +0, r = +0, l = +0), "cm"),
    plot.title = element_text(size = 18),
    plot.title.position = "plot",
    plot.subtitle = element_text(size = 16),
    plot.caption = element_text(size = 12)
  )
}
```


To get an idea of the accuracy of our model, below is a plot of 50 randomly sampled data points from our test data with our model's prediction.
```{r}

plot <- sample_n(final, 50) %>%
  arrange(Actual) %>%
  rowid_to_column("ID") %>%
  ggplot(aes(ID, Actual)) +
  geom_point(aes(color = "black")) +
  geom_point(aes(ID, Predicted, color = "red")) +
  geom_errorbar(aes(ymin = Actual, 
                    ymax = Predicted, 
                    colour = "red"
                    ), position=position_dodge(.9)) +
  theme_error() +
  labs(title="Prediction Error of 50 Random Counties",
       x = "Randomly Selected County",
       y = "Diabetes Rate ") +
  scale_color_manual(values = c("black", "red"),
                     labels = c("Actual", "Predicted"))
plot
  
```




## Uncertainty
*address sources of uncertainty which are potentially outside the scope of what's already been discussed*
While we did account for uncertainty in our correlation coefficient calculation, there are still many sources uncertainty that we did not consider. The largest source is from the dataset itself. The values contained in the dataset are estimates themselves, and come with some level of uncertainty. For example, we found that the measure of food insecurity was estimated with a 90% confidence interval. This error reduces our certainty in our final results. 


## Conclusion - Shawn




## Sources
[1] https://www.ers.usda.gov/data-products/food-environment-atlas/data-access-and-documentation-downloads/#Current%20Version  
[2] https://www.ers.usda.gov/webdocs/DataFiles/80526/2017%20Food%20Environment%20Atlas%20Documentation.pdf?v=1143.5  
[3] https://rstatisticsblog.com/data-science-in-action/machine-learning/lasso-regression/  
[4] https://www.steveklosterman.com/over-under/  
[5] http://www.science.smith.edu/~jcrouser/SDS293/labs/lab10-r.html  
[6] https://www.cdc.gov/diabetes/pdfs/data/statistics/national-diabetes-statistics-report.pdf
[7] https://cran.r-project.org/web/packages/glmnet/glmnet.pdf
[8] https://www.pluralsight.com/guides/linear-lasso-and-ridge-regression-with-r


